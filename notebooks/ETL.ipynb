{
 "cells": [
  {
   "cell_type": "raw",
   "id": "22dd7831-f71b-4056-a0ed-afa5d75c5b2f",
   "metadata": {},
   "source": [
    "DATA INGESTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a818f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '9T0G08ZXDQTVYW2D', 'HostId': 'scs/OT8gGEMMlFQL6Jv7YLnud9jDCrI69ucydu66wnIFSezAahZCtQaxQItHXZ5P2jWe3l30nbo=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'scs/OT8gGEMMlFQL6Jv7YLnud9jDCrI69ucydu66wnIFSezAahZCtQaxQItHXZ5P2jWe3l30nbo=', 'x-amz-request-id': '9T0G08ZXDQTVYW2D', 'date': 'Mon, 17 Feb 2025 08:32:48 GMT', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'Buckets': [{'Name': 'aws-a9097-use1-00-d-s3b-shrd-shr-data01', 'CreationDate': datetime.datetime(2024, 8, 6, 8, 41, 20, tzinfo=tzlocal())}, {'Name': 'cf-templates-1jlshq8udppq6-us-east-1', 'CreationDate': datetime.datetime(2024, 8, 1, 10, 43, 34, tzinfo=tzlocal())}], 'Owner': {'DisplayName': 'aws.a9097', 'ID': '6d9499ce97be2b4c12d262e50a6c0e45aa4f21142385c704f4dffe905958950b'}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize S3 client and configuration variables\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'aws-a9097-use1-00-d-s3b-shrd-shr-data01'\n",
    "IAM_ROLE = 'aws-a9097-use1-00-d-rol-shrd-shr-usr01'\n",
    "\n",
    "# List all S3 buckets and print the response\n",
    "check_response = s3_client.list_buckets()\n",
    "print(check_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343fbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = ['GeoHiery.txt', 'MarketDefinition.txt', 'Prescriber.txt', 'PrescriberAddress.txt', 'ProductMaster.txt', 'Sales.txt', 'Zip_To_Terr.txt']\n",
    "\n",
    "# Upload each file in files_list to S3 bucket under 'raw/' prefix\n",
    "for file in files_list:\n",
    "    s3_client.upload_file(file, bucket_name, f'raw/{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83943d8",
   "metadata": {},
   "source": [
    "EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ef30be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GEO_CODE    GEO_NAME GEO_LEVEL PARENT_ID\n",
      "0  T-111100      Acampo      TERR  D-111000\n",
      "1  D-111000  District 1      DIST  R-110000\n",
      "2  R-110000          CA      REGN  N-100000\n",
      "3  N-100000         USA    NATION         -\n",
      "4  T-111200       Acton      TERR  D-111000\n",
      "  MKT_CD          MKT_NM\n",
      "0  M-001    NEUROSCIENCE\n",
      "1  M-002        VIROLOGY\n",
      "2  M-003      IMMUNOLOGY\n",
      "3  M-004      HEMATOLOGY\n",
      "4  M-005  CARDIOVASCULAR\n",
      "  Prescriber_ID FIRST_NAME  LAST_NAME         PREFFERED_NAME  GENDER  EMAIL  \\\n",
      "0      ST_00001   SOONTORN  THRUPKAEW     SOONTORN THRUPKAEW     NaN    NaN   \n",
      "1      RB_00002     ROBERT      BRYAN           ROBERT BRYAN     NaN    NaN   \n",
      "2      JC_00003       JOHN     CARTER  JOHN JEFFERSON CARTER     NaN    NaN   \n",
      "3      TK_00004   THEODORE   KIRKLAND    THEODORE N KIRKLAND     NaN    NaN   \n",
      "4      TC_00005        TOM   CALDWELL           TOM CALDWELL     NaN    NaN   \n",
      "\n",
      "   PERSON_SPECIALTY  \n",
      "0  GastroEnterology  \n",
      "1         NeuroLogy  \n",
      "2       Dermatology  \n",
      "3         NeuroLogy  \n",
      "4        Psychiatry  \n",
      "  PERSON_CODE              ADDRESS_1  ADDRESS_2    CITY STATE  ZIP_CODE\n",
      "0    ST_00001           1 BAYLOR PLZ        NaN  Acampo    CA         1\n",
      "1    RB_00002           1 BETHANY RD        NaN  Acampo    CA         2\n",
      "2    JC_00003  1 BETHANY RD SUITE 11        NaN  Acampo    CA         3\n",
      "3    TK_00004   1 BETHANY RD SUITE 3        NaN  Acampo    CA         4\n",
      "4    TC_00005  1 BETHANY RD SUITE 35        NaN  Acampo    CA         5\n",
      "  MARKET_CD  PRD_PACK_ID    PRODUCT_NAME STRENGTH  BRAND_ID Brand Name  \\\n",
      "0     M-001      1001001  ATRIPXEN 350mg    350mg      1001  ATRIPIXEN   \n",
      "1     M-001      1001002  ATRIPXEN 500mg    500mg      1001  ATRIPIXEN   \n",
      "2     M-001      1002001     BRUFEN 50mg     50mg      1002     BRUFEN   \n",
      "3     M-001      1002002    BRUFEN 100mg    100mg      1002     BRUFEN   \n",
      "4     M-001      1003001  CLOPIGEL 100mg    100mg      1003   CLOPIGEL   \n",
      "\n",
      "     PROD_MNF  \n",
      "0  ABC_Pharma  \n",
      "1  ABC_Pharma  \n",
      "2  DEF_Pharma  \n",
      "3  DEF_Pharma  \n",
      "4  GHI_Pharma  \n",
      "    PSBR_ID  PROD_ID  MONTH_1_NRX_UNIT  MONTH_2_NRX_UNIT  MONTH_3_NRX_UNIT  \\\n",
      "0  ST_00001  1003002                 3                 8                 7   \n",
      "1  RB_00002  1002001                 9                 8                 7   \n",
      "2  JC_00003  1007002                 7                 1                 3   \n",
      "3  TK_00004  1010001                 6                 3                 5   \n",
      "4  TC_00005  1010001                 9                 7                 6   \n",
      "\n",
      "   MONTH_4_NRX_UNIT  MONTH_5_NRX_UNIT  MONTH_6_NRX_UNIT  MONTH_7_NRX_UNIT  \\\n",
      "0                 6                 6                 9                 3   \n",
      "1                 8                 3                 2                 4   \n",
      "2                 1                 9                 9                 8   \n",
      "3                 2                 2                 3                 4   \n",
      "4                 6                 1                 5                 2   \n",
      "\n",
      "   MONTH_8_NRX_UNIT  ...  MONTH_3_TRX_DOLLAR  MONTH_4_TRX_DOLLAR  \\\n",
      "0                 3  ...                 880                4200   \n",
      "1                 3  ...                1440                 640   \n",
      "2                 2  ...                2046                 726   \n",
      "3                 7  ...                2856                1260   \n",
      "4                 2  ...                2352                1638   \n",
      "\n",
      "   MONTH_5_TRX_DOLLAR  MONTH_6_TRX_DOLLAR  MONTH_7_TRX_DOLLAR  \\\n",
      "0                 480                2600                2240   \n",
      "1                1920                1000                1080   \n",
      "2                1188                3729                2244   \n",
      "3                1218                1008                3150   \n",
      "4                1134                2352                 462   \n",
      "\n",
      "   MONTH_8_TRX_DOLLAR  MONTH_9_TRX_DOLLAR  MONTH_10_TRX_DOLLAR  \\\n",
      "0                2920                 560                 2680   \n",
      "1                2960                3960                 3320   \n",
      "2                2475                 693                 1089   \n",
      "3                4998                2352                 1638   \n",
      "4                1764                1218                 2730   \n",
      "\n",
      "   MONTH_11_TRX_DOLLAR  MONTH_12_TRX_DOLLAR  \n",
      "0                  800                  400  \n",
      "1                  880                 1960  \n",
      "2                 2310                 3069  \n",
      "3                 2310                 1680  \n",
      "4                 1638                 1932  \n",
      "\n",
      "[5 rows x 110 columns]\n",
      "   ZIP_Code Territory_ID\n",
      "0         1     T-111100\n",
      "1         2     T-111100\n",
      "2         3     T-111100\n",
      "3         4     T-111100\n",
      "4         5     T-111100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "for file in files_list:\n",
    "    # Construct S3 file path and read CSV with pipe delimiter\n",
    "    s3_file = f's3://{bucket_name}/raw/{file}'\n",
    "    df = pd.read_csv(s3_file, delimiter='|')\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d79f3e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDSHIFT CREDS LOADED\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Redshift connection credentials\n",
    "REDSHIFT_HOST = 'aws-a9097-use1-00-d-red-shrd-shr-red01.ca3wdeu8uqbl.us-east-1.redshift.amazonaws.com'\n",
    "REDSHIFT_DB = 'dev'\n",
    "REDSHIFT_USER = 'group1user'\n",
    "REDSHIFT_PORT = '5439'\n",
    "REDSHIFT_PASSWORD = 'Group1pass'\n",
    "\n",
    "\"\"\"\n",
    "Establishes a connection to Redshift using the provided credentials.\n",
    "Returns a connection object that can be used to execute queries.\n",
    "\"\"\"\n",
    "conn = psycopg2.connect(dbname=REDSHIFT_DB,\n",
    "                       user=REDSHIFT_USER,\n",
    "                       password=REDSHIFT_PASSWORD,\n",
    "                       host=REDSHIFT_HOST,\n",
    "                       port=REDSHIFT_PORT)\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Test connection by executing a simple query\n",
    "cursor.execute(\"SELECT current_date\")\n",
    "print('REDSHIFT CREDS LOADED SUCESSFULLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbb6e48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoHiery.txt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(io\u001b[38;5;241m.\u001b[39mbytesIO(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files_list:\n\u001b[0;32m---> 10\u001b[0m     df[file]\u001b[38;5;241m=\u001b[39m\u001b[43mextractFromS3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m, in \u001b[0;36mextractFromS3\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_name)\n\u001b[1;32m      6\u001b[0m obj \u001b[38;5;241m=\u001b[39m s3_client\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39mbucket_name , Key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mbytesIO(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating respective dataframes to work with for EXTRACT\n",
    "\n",
    "\n",
    "def extractFromS3(file_name):\n",
    "    \"\"\"Extract a CSV file from S3 bucket and return it as a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the file to extract from S3 bucket\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the data from the CSV file\n",
    "    \"\"\"\n",
    "    print(file_name)\n",
    "    obj = s3_client.get_object(Bucket=bucket_name, Key=f'raw/{file}')\n",
    "    return pd.read_csv(io.bytesIO(obj['Body'].read()))\n",
    "\n",
    "for file in files_list:\n",
    "    df[file] = extractFromS3(file)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82382bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InFailedSqlTransaction",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInFailedSqlTransaction\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m sql1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mCREATE TABLE IF NOT EXISTS bs_grp1_person_profile(\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m    Prescriber_ID VARCHAR(50),\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    FIRST_NAME VARCHAR(100),\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    PERSON_SPECIALTY VARCHAR(100)\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m);\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[0;31mInFailedSqlTransaction\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "sql1 = f'''CREATE TABLE IF NOT EXISTS bs_grp1_person_profile(\n",
    "    Prescriber_ID VARCHAR(50),\n",
    "    FIRST_NAME VARCHAR(100),\n",
    "    LAST_NAME VARCHAR(100),\n",
    "    PREFFERED_NAME VARCHAR(100),\n",
    "    GENDER VARCHAR(10),\n",
    "    EMAIL VARCHAR(100),\n",
    "    PERSON_SPECIALTY VARCHAR(100)\n",
    ");'''\n",
    "\n",
    "# Execute SQL statement to create person profile table if it doesn't exist\n",
    "cursor.execute(sql1)\n",
    "\n",
    "# Commit the transaction to make changes persistent\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f1735dc-adec-4672-8b24-36b0fcfcd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql1 = '''CREATE TABLE IF NOT EXISTS bs_grp1_person_profile(\n",
    "    Prescriber_ID VARCHAR(50),\n",
    "    FIRST_NAME VARCHAR(100),\n",
    "    LAST_NAME VARCHAR(100),\n",
    "    PREFFERED_NAME VARCHAR(100),\n",
    "    GENDER VARCHAR(10),\n",
    "    EMAIL VARCHAR(100),\n",
    "    PERSON_SPECIALTY VARCHAR(100)\n",
    ");'''\n",
    "\n",
    "# Rollback any previous failed transaction to ensure clean state\n",
    "conn.rollback()\n",
    "\n",
    "# Execute the CREATE TABLE statement for person profile data\n",
    "cursor.execute(sql1)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ee3579a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql2 = '''\n",
    "COPY bs_grp1_person_profile\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/Prescriber.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1\n",
    "REMOVEQUOTES\n",
    "EMPTYASNULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642'\n",
    ";\n",
    "'''\n",
    "\n",
    "# Rollback any previous failed transaction to ensure clean state\n",
    "conn.rollback()\n",
    "\n",
    "# Execute the COPY command to load data from S3 into Redshift table\n",
    "cursor.execute(sql2)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "235a04ba-7563-488f-a77d-e970d2ad6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created prod_master\n"
     ]
    },
    {
     "ename": "InternalError_",
     "evalue": "Load into table 'bs_grp1_prod_master' failed.  Check 'stl_load_errors' system table for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError_\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m conn\u001b[38;5;241m.\u001b[39mrollback()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Execute the CREATE TABLE statement\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loaded in table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mInternalError_\u001b[0m: Load into table 'bs_grp1_prod_master' failed.  Check 'stl_load_errors' system table for details.\n"
     ]
    }
   ],
   "source": [
    "sql_create = '''CREATE TABLE IF NOT EXISTS bs_grp1_prod_master(\n",
    "    MARKET_CD VARCHAR(10),\n",
    "    PRD_PACK_ID VARCHAR(50),\n",
    "    PRODUCT_NAME VARCHAR(200),\n",
    "    IMS_STRENG VARCHAR(50),\n",
    "    TH_LEVEL VARCHAR(50),\n",
    "    BRAND_ID VARCHAR(50),\n",
    "    BRAND_NAME VARCHAR(100),\n",
    "    PROD_MNF VARCHAR(100)\n",
    ");'''\n",
    "\n",
    "# Rollback any previous failed transaction to ensure clean state before execution\n",
    "conn.rollback()\n",
    "\n",
    "# Execute the CREATE TABLE statement\n",
    "cursor.execute(sql_create)\n",
    "conn.commit()\n",
    "print(\"Successfully created prod_master\")\n",
    "\n",
    "sql_copy = '''\n",
    "COPY bs_grp1_prod_master\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/Prescriber.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1\n",
    "REMOVEQUOTES\n",
    "EMPTYASNULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642'\n",
    ";\n",
    "'''\n",
    "\n",
    "# Rollback any previous failed transaction to ensure clean state before data load\n",
    "conn.rollback()\n",
    "\n",
    "# Execute the COPY command to load data from S3 into Redshift table\n",
    "cursor.execute(sql_copy)\n",
    "conn.commit()\n",
    "print(\"Data loaded in table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7d8770a8-f963-455d-bd94-3c6c6d2fc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bs_grp1_person_address successfully!\n",
      "Data loaded into bs_grp1_person_address from S3!\n"
     ]
    }
   ],
   "source": [
    "#create_person_address\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bs_grp1_person_address (\n",
    "    PERSON_CODE VARCHAR(50),\n",
    "    ADDRESS_1 VARCHAR(200),\n",
    "    ADDRESS_2 VARCHAR(200),\n",
    "    CITY VARCHAR(100),\n",
    "    STATE VARCHAR(50),\n",
    "    ZIP_CODE VARCHAR(10)\n",
    ");\n",
    "\"\"\"\n",
    "conn.rollback()  # Ensure clean state before table creation\n",
    "cursor.execute(sql_create)\n",
    "conn.commit()\n",
    "print(\"Created table bs_grp1_person_address successfully!\")\n",
    "\n",
    "# COPY FROM S3\n",
    "sql_copy = \"\"\"\n",
    "COPY bs_grp1_person_address\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/PrescriberAddress.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1  # Skip header row\n",
    "EMPTYASNULL    # Treat empty fields as NULL\n",
    "BLANKSASNULL   # Treat blank fields as NULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642';\n",
    "\"\"\"\n",
    "conn.rollback()  # Ensure clean state before data load\n",
    "cursor.execute(sql_copy)\n",
    "conn.commit()\n",
    "print(\"Data loaded into bs_grp1_person_address from S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d3505c33-4350-4962-aafe-a7d12250b960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bs_grp1_geo_hierarchy successfully!\n",
      "Data loaded into bs_grp1_geo_hierarchy from S3!\n"
     ]
    }
   ],
   "source": [
    "# CREATE TABLE_geo_hierachy\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bs_grp1_geo_hierarchy (\n",
    "    GEO_CODE   VARCHAR(50),\n",
    "    GEO_NAME   VARCHAR(100),\n",
    "    GEO_LEVEL  VARCHAR(20),\n",
    "    PARENT_ID  VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_create)\n",
    "conn.commit()\n",
    "print(\"Created table bs_grp1_geo_hierarchy successfully!\")\n",
    "\n",
    "# COPY data from S3 to Redshift table\n",
    "sql_copy = \"\"\"\n",
    "COPY bs_grp1_geo_hierarchy\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/GeoHiery.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1\n",
    "REMOVEQUOTES\n",
    "EMPTYASNULL\n",
    "BLANKSASNULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642';\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_copy)\n",
    "conn.commit()\n",
    "print(\"Data loaded into bs_grp1_geo_hierarchy from S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0a0da2ba-df9c-455e-9238-437423a4a511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bs_grp1_zip_terr successfully!\n",
      "Data loaded into bs_grp1_zip_terr from S3!\n"
     ]
    }
   ],
   "source": [
    "# CREATE TABLE\n",
    "sql_create3 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bs_grp1_zip_terr (\n",
    "    ZIP_Code      VARCHAR(10),\n",
    "    Territory_ID  VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_create3)\n",
    "conn.commit()\n",
    "print(\"Created table bs_grp1_zip_terr successfully!\")\n",
    "\n",
    "# COPY data from S3 to Redshift table\n",
    "sql_copy3 = \"\"\"\n",
    "COPY bs_grp1_zip_terr\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/Zip_To_Terr.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1\n",
    "REMOVEQUOTES\n",
    "EMPTYASNULL\n",
    "BLANKSASNULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642';\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_copy3)\n",
    "conn.commit()\n",
    "print(\"Data loaded into bs_grp1_zip_terr from S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c38f8f0-83ff-49b4-a133-057c63aa183e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bs_grp1_sales successfully!\n",
      "Data loaded into bs_grp1_sales from S3!\n"
     ]
    }
   ],
   "source": [
    "# CREATE TABLE: SQL statement to create bs_grp1_sales table if it doesn't exist\n",
    "sql_create2 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bs_grp1_sales (\n",
    "    PSBR_ID          VARCHAR(50),\n",
    "    PROD_ID          VARCHAR(50),\n",
    "    MONTH_1_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_2_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_3_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_4_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_5_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_6_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_7_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_8_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_9_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_10_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_11_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_12_NRX_UNIT   VARCHAR(50),\n",
    "    MONTH_1_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_2_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_3_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_4_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_5_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_6_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_7_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_8_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_9_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_10_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_11_TRX_UNIT   VARCHAR(50),\n",
    "    MONTH_12_TRX_UNIT   VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_create2)\n",
    "conn.commit()\n",
    "print(\"Created table bs_grp1_sales successfully!\")\n",
    "\n",
    "# COPY: SQL statement to load data from S3 into bs_grp1_sales table\n",
    "sql_copy2 = \"\"\"\n",
    "COPY bs_grp1_sales\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/Sales.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1\n",
    "REMOVEQUOTES\n",
    "EMPTYASNULL\n",
    "BLANKSASNULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642';\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_copy2)\n",
    "conn.commit()\n",
    "print(\"Data loaded into bs_grp1_sales from S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf0c408f-2d73-4566-ae43-7c54a7ee88bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bs_grp1_mkt_desc successfully!\n",
      "Data loaded into bs_grp1_mkt_desc from S3!\n"
     ]
    }
   ],
   "source": [
    "# CREATE THE TABLE\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bs_grp1_mkt_desc (\n",
    "    MKT_CD  VARCHAR(10),\n",
    "    MKT_NM  VARCHAR(200)\n",
    ");\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_create)\n",
    "conn.commit()\n",
    "print(\"Created table bs_grp1_mkt_desc successfully!\")\n",
    "\n",
    "# COPY THE TABLE\n",
    "sql_copy = \"\"\"\n",
    "COPY bs_grp1_mkt_desc\n",
    "FROM 's3://aws-a9097-use1-00-d-s3b-shrd-shr-data01/raw/MarketDefinition.txt'\n",
    "DELIMITER '|'\n",
    "IGNOREHEADER 1\n",
    "REMOVEQUOTES\n",
    "EMPTYASNULL\n",
    "BLANKSASNULL\n",
    "IAM_ROLE 'arn:aws:iam::014498666895:role/service-role/AmazonRedshift-CommandsAccessRole-20240806T150642';\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "cursor.execute(sql_copy)\n",
    "conn.commit()\n",
    "print(\"Data loaded into bs_grp1_mkt_desc from S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a515b42-76b4-4599-b3c3-a753f23b8708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
